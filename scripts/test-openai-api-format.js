#!/usr/bin/env node

/**
 * OpenAI APIæ ¼å¼æµ‹è¯•è„šæœ¬
 * éªŒè¯OpenAI GPT-OSSæ¨¡å‹çš„APIè°ƒç”¨æ ¼å¼ä¿®å¤
 */

console.log('ğŸ§ª OpenAI APIæ ¼å¼ä¿®å¤éªŒè¯');
console.log('================================================================================');

// æ¨¡æ‹Ÿchat.tsä¸­çš„APIæ ¼å¼è½¬æ¢é€»è¾‘
function testApiFormat(model, messagesWithEnhancedSystem) {
  console.log(`\nğŸ¤– æµ‹è¯•æ¨¡å‹: ${model}`);
  console.log('------------------------------------------------------------');
  
  if (model.includes('@cf/openai/gpt-oss')) {
    console.log('âœ… æ£€æµ‹åˆ°OpenAI GPT-OSSæ¨¡å‹ï¼Œä½¿ç”¨instructions + inputæ ¼å¼');
    
    // OpenAIå¼€æºæ¨¡å‹ä½¿ç”¨instructions + inputæ ¼å¼
    const systemMessage = messagesWithEnhancedSystem.find(m => m.role === 'system');
    const userMessages = messagesWithEnhancedSystem.filter(m => m.role !== 'system');
    const conversationInput = userMessages.map(m => `${m.role}: ${m.content}`).join('\n');
    
    const apiCall = {
      instructions: systemMessage ? systemMessage.content : 'DEFAULT_SYSTEM_PROMPT',
      input: conversationInput,
      stream: true,
      max_tokens: 4096,
      temperature: 0.8
    };
    
    console.log('ğŸ“ APIè°ƒç”¨å‚æ•°:');
    console.log(`  - instructions: "${apiCall.instructions.substring(0, 80)}..."`);
    console.log(`  - input: "${apiCall.input}"`);
    console.log(`  - stream: ${apiCall.stream}`);
    console.log(`  - max_tokens: ${apiCall.max_tokens}`);
    console.log(`  - temperature: ${apiCall.temperature}`);
    
    return apiCall;
  } else {
    console.log('âœ… æ£€æµ‹åˆ°éOpenAIæ¨¡å‹ï¼Œä½¿ç”¨æ ‡å‡†messagesæ ¼å¼');
    
    const apiCall = {
      messages: messagesWithEnhancedSystem,
      stream: true,
      max_tokens: 4096,
      temperature: 0.8,
      top_p: 0.95
    };
    
    console.log('ğŸ“ APIè°ƒç”¨å‚æ•°:');
    console.log(`  - messages: [${apiCall.messages.length} æ¡æ¶ˆæ¯]`);
    console.log(`  - stream: ${apiCall.stream}`);
    console.log(`  - max_tokens: ${apiCall.max_tokens}`);
    console.log(`  - temperature: ${apiCall.temperature}`);
    console.log(`  - top_p: ${apiCall.top_p}`);
    
    return apiCall;
  }
}

// æµ‹è¯•æ•°æ®
const testMessages = [
  {
    role: 'system',
    content: 'You are SVTR.AI assistant for AI venture investment analysis.'
  },
  {
    role: 'user', 
    content: 'Tell me about Anthropic investment situation'
  },
  {
    role: 'assistant',
    content: 'Anthropic has received significant funding...'
  },
  {
    role: 'user',
    content: 'What about their latest funding round?'
  }
];

const testModels = [
  '@cf/openai/gpt-oss-120b',
  '@cf/openai/gpt-oss-20b', 
  '@cf/meta/llama-3.3-70b-instruct',
  '@cf/qwen/qwen2.5-coder-32b-instruct'
];

// æ‰§è¡Œæµ‹è¯•
testModels.forEach(model => {
  testApiFormat(model, testMessages);
});

console.log('\nğŸ“Š æµ‹è¯•æ€»ç»“:');
console.log('================================================================================');
console.log('âœ… APIæ ¼å¼ä¿®å¤å·²å®Œæˆ:');
console.log('  â€¢ OpenAI GPT-OSSæ¨¡å‹: ä½¿ç”¨instructions + inputæ ¼å¼');
console.log('  â€¢ å…¶ä»–æ¨¡å‹: ä½¿ç”¨æ ‡å‡†messagesæ ¼å¼');
console.log('  â€¢ è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹å¹¶åº”ç”¨å¯¹åº”æ ¼å¼');

console.log('\nğŸ” å…³é”®ä¿®å¤ç‚¹:');
console.log('1. æ£€æµ‹æ¨¡å‹åç§°åŒ…å«"@cf/openai/gpt-oss"');
console.log('2. æå–system messageä½œä¸ºinstructions');
console.log('3. åˆå¹¶user/assistant messagesä¸ºå•ä¸€input');
console.log('4. ç§»é™¤ä¸æ”¯æŒçš„top_på‚æ•°ï¼ˆOpenAIæ¨¡å‹ï¼‰');

console.log('\nğŸš€ é¢„æœŸæ•ˆæœ:');
console.log('â€¢ OpenAI GPT-OSSæ¨¡å‹ç°åœ¨åº”è¯¥èƒ½æ­£ç¡®å“åº”');
console.log('â€¢ æ›´å¥½çš„æ¨ç†å’Œä»£ç ç”Ÿæˆèƒ½åŠ›');
console.log('â€¢ æµå¼å“åº”æ­£å¸¸å·¥ä½œ');
console.log('â€¢ Fallbackæœºåˆ¶ä¿æŒå®Œæ•´');

console.log('\nâš ï¸  æ³¨æ„äº‹é¡¹:');
console.log('â€¢ OpenAIæ¨¡å‹å¯èƒ½æœ‰ä¸åŒçš„å“åº”æ ¼å¼');
console.log('â€¢ éœ€è¦æµ‹è¯•æµå¼å“åº”è§£ææ˜¯å¦æ­£ç¡®');
console.log('â€¢ ç›‘æ§æ¨¡å‹åˆ‡æ¢å’Œé”™è¯¯å¤„ç†');